{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"AUTOMATIC_TICKET_ASSIGNMENT_FINAL_SUBMISSION_BERT.ipynb","provenance":[],"collapsed_sections":["pTu9McUTjcu8","QcmtNtfLjcvB","BK2wmbNLjcvC","7QlCQERWjcvD","HKasY_g9jcvN","Yyq-3BU0jcyj","-baiibrz9L4N","orvFUXV09auF","W7we6P9L9kXv","sZr_lzrsAGk4"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pTu9McUTjcu8","colab_type":"text"},"source":["# Capstone : IT Ticket Classification [SEPT SUN GRP 4B]"]},{"cell_type":"markdown","metadata":{"id":"S4URHCrWjcu9","colab_type":"text"},"source":["![1_yK5G9nHmOD-wrJSRSvPEpw.jpeg](attachment:1_yK5G9nHmOD-wrJSRSvPEpw.jpeg)"]},{"cell_type":"markdown","metadata":{"id":"IOYkXd9Pjcu_","colab_type":"text"},"source":["# Aim: Automatic Ticket Assignment [Part /6]"]},{"cell_type":"markdown","metadata":{"id":"Dpax96BHjcvA","colab_type":"text"},"source":["\n","Build a classifier that can classify the tickets by analyzing text. Classify incidents to right functional groups can help organizations to reduce the resolving time of the issue and can focus on more productive tasks."]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"QcmtNtfLjcvB","colab_type":"text"},"source":["## Pre-Processing, Data Visualization and EDA"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"M4F3uBicjcvB","colab_type":"text"},"source":["- Exploring the given Data files\n","- Understanding the structure of data\n","- Missing points in data\n","- Finding inconsistencies in the data\n","- Visualizing different patterns\n","- Visualizing different text features\n","- Dealing with missing values\n","- Text preprocessing\n","- Creating word vocabulary from the corpus of report text data\n","- Creating tokens as required"]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"BK2wmbNLjcvC","colab_type":"text"},"source":["## Model Building"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"0A5bLTgZjcvC","colab_type":"text"},"source":["- Building a BERT model architecture using Ktrain which can classify the tickets accordingly\n","- BERT is a method of pre-training language representations, meaning that we train a general-purpose \"language understanding\" model on a large text corpus (like Wikipedia), and then use that model for downstream NLP tasks that we care about (like question answering). BERT outperforms previous methods because it is the first unsupervised, deeply bidirectional system for pre-training NLP. Unsupervised means that BERT was trained using only a plain text corpus, which is important because an enormous amount of plain text data is publicly available on the web in many languages. Pre-trained representations can also either be context-free or contextual, and contextual representations can further be unidirectional or bidirectional. Context-free models such as word2vec or GloVe generate a single \"word embedding\" representation for each word in the vocabulary, so bank would have the same representation in bank deposit and river bank. Contextual models instead generate a representation of each word that is based on the other words in the sentence. https://github.com/google-research/bert/blob/master/README.md\n","- Save the model for reload and prediction without having to run the model again."]},{"cell_type":"markdown","metadata":{"id":"7QlCQERWjcvD","colab_type":"text"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"id":"zn1xza-9zxDT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b8587daf-8d42-44b5-cc22-ea1ea65d430a"},"source":["!pip install ktrain"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting ktrain\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/a3/9bb8c202f8f20171fb54a1991796ea95e4af0020afc13890f4ba4092dede/ktrain-0.20.1.tar.gz (25.3MB)\n","\u001b[K     |████████████████████████████████| 25.3MB 128kB/s \n","\u001b[?25hCollecting tensorflow==2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 35kB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.22.2.post1)\n","Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.2)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.5)\n","Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.0)\n","Collecting keras_bert>=0.81.0\n","  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.23.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.16.0)\n","Collecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n","\u001b[K     |████████████████████████████████| 983kB 41.8MB/s \n","\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n","Collecting cchardet\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/c5/7e1a0d7b4afd83d6f8de794fce82820ec4c5136c6d52e14000822681a842/cchardet-2.1.6-cp36-cp36m-manylinux2010_x86_64.whl (241kB)\n","\u001b[K     |████████████████████████████████| 245kB 50.1MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.4)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.1)\n","Collecting seqeval\n","  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.4)\n","Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.0)\n","Collecting transformers>=2.11.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 40.0MB/s \n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n","Collecting syntok\n","  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n","Collecting whoosh\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n","\u001b[K     |████████████████████████████████| 471kB 44.6MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.1)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.35.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.3.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.12.4)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.31.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.4.1)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.2.0)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 42.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.18.5)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 43.9MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n","Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras_bert>=0.81.0->ktrain) (2.4.3)\n","Collecting keras-transformer>=0.38.0\n","  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.3->ktrain) (4.4.2)\n","Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (2.11.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.7.4.2)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.13)\n","Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (7.0.0)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (5.1.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (4.41.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.16.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (20.1.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (2.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.3.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (2019.12.20)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 38.5MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 40.6MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (0.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 47.5MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (3.0.12)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.1.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (49.6.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain) (2.10.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.0.1)\n","Collecting keras-pos-embd>=0.11.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.27.0\n","  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n","Collecting keras-layer-normalization>=0.14.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n","Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->ktrain) (1.52.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.11.0->ktrain) (7.1.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.6)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.7.0)\n","Collecting keras-self-attention==0.46.0\n","  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n","Building wheels for collected packages: ktrain, keras-bert, langdetect, seqeval, syntok, gast, keras-transformer, sacremoses, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ktrain: filename=ktrain-0.20.1-cp36-none-any.whl size=25269103 sha256=836f96401b4f754abce33a66cede5c71d14607b45272f5c39951c88d81836cde\n","  Stored in directory: /root/.cache/pip/wheels/d7/b6/1f/3abc6cafe229d646a780c8af15a05e6ce753d5e5d0cb4d1074\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp36-none-any.whl size=34145 sha256=1ea2a4a16ab4991f60100c1af6cb5fad02b81c5689164d2b4065567e99fa6f6d\n","  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=f4b68535aa8010184df047cbbba78f305fa812c949671d88f784b2de02d0c111\n","  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7423 sha256=0e19285d375db21bd3d518c352192ad18868ed1c045decc2f64fe748b3f5d1b5\n","  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n","  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for syntok: filename=syntok-1.3.1-cp36-none-any.whl size=20919 sha256=abedc296d5fc83aa46130e6b7024322a2d9c1abbaa68e41100074945c9d3dec8\n","  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=9b5776fdd4bf67c12d13f8c0240c4bcbf831b017f82c9ce7571f2b353246a3b6\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=11773385488096b7d24c75a0332a5414e27b62e249b689bd2db0b45424d656fe\n","  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2aa8fc3e00778d5750882b9c7702a350935b3688fe2bd5d1b76c205f7dc9be1a\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=add0f215e165657fce0d8b37c5779d138584f5cb9cb36837d03609b4aa5fc826\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15612 sha256=f928d4a0c3fa8e51d3a4656acccbf06e5ce23abdd9c0540186534de71f7dabd3\n","  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=1caade1b9493aa96e64053ea4ff6cddcd2ae9b303437563cc4387f7efbf47f1d\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5626 sha256=079b17cfced12ae106252cb08efbc1401c185ce95571d05c08e659f8907a6843\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4559 sha256=e3b5a37edcb7d47a238be3e7030761074ea9cfbcf9e3cbc67575e8d5abe35a41\n","  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=3450e940671ff6b10c75501c3ba6f5e7ae68c3866f17b6187cdfa20469a1c87c\n","  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n","Successfully built ktrain keras-bert langdetect seqeval syntok gast keras-transformer sacremoses keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast, keras-applications, tensorflow-estimator, tensorboard, tensorflow, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, cchardet, seqeval, sentencepiece, tokenizers, sacremoses, transformers, syntok, whoosh, ktrain\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed cchardet-2.1.6 gast-0.2.2 keras-applications-1.0.8 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.20.1 langdetect-1.0.8 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-0.0.12 syntok-1.3.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tokenizers-0.8.1rc1 transformers-3.0.2 whoosh-2.7.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hguloJBnjcvD","colab_type":"code","colab":{}},"source":["#Bert Model using KTrain\n","import ktrain\n","from ktrain import text\n","import pandas as pd \n","import numpy as np \n","import tensorflow as tf\n","import sys"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VhquMOeIjcvI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"4b1ed348-0b5f-430f-ad3f-791c015e3374"},"source":["np.__version__ , pd.__version__,tf.__version__, print(sys.version_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('1.18.5', '1.0.5', '2.1.0', None)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"HKasY_g9jcvN","colab_type":"text"},"source":["# Data Loading"]},{"cell_type":"markdown","metadata":{"id":"nkWjS8j-8s_q","colab_type":"text"},"source":["Data File used for Bert DL Model using KTrain contains cleaned data with records for all 74 classes which are unsampled \n"]},{"cell_type":"code","metadata":{"id":"xb-Pra4EjcvO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"f01feff4-5279-4f04-8fb5-e106e1163c3c"},"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","project_path = '/content/drive/My Drive/Colab Notebooks/'\n","file_name ='itsupportdatacleaned_2.csv'\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sTebfUcujcvR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"d94c0f09-5e67-4519-98e0-d9687c50e296"},"source":["data=pd.read_csv(project_path+file_name,encoding=sys.getfilesystemencoding()) \n","data.head(2).T"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Short description</th>\n","      <td>login issue</td>\n","      <td>outlook</td>\n","    </tr>\n","    <tr>\n","      <th>Description</th>\n","      <td>login issue verify user detail employee manage...</td>\n","      <td>outlook hello team meeting skype meeting etc a...</td>\n","    </tr>\n","    <tr>\n","      <th>Caller</th>\n","      <td>spxjnwir pjlcoqds</td>\n","      <td>hmjdrvpb komuaywn</td>\n","    </tr>\n","    <tr>\n","      <th>Assignment group</th>\n","      <td>GRP_0</td>\n","      <td>GRP_0</td>\n","    </tr>\n","    <tr>\n","      <th>New_Assignment_Groups</th>\n","      <td>GRP_0</td>\n","      <td>GRP_0</td>\n","    </tr>\n","    <tr>\n","      <th>Text_length</th>\n","      <td>206</td>\n","      <td>194</td>\n","    </tr>\n","    <tr>\n","      <th>Dominant_Topic</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Topic_Perc_Contrib</th>\n","      <td>0.9912</td>\n","      <td>0.6753</td>\n","    </tr>\n","    <tr>\n","      <th>Keywords</th>\n","      <td>issue, tool, unable, user, error, work, access...</td>\n","      <td>issue, tool, unable, user, error, work, access...</td>\n","    </tr>\n","    <tr>\n","      <th>Text</th>\n","      <td>['login', 'issue', 'verify', 'user', 'detail',...</td>\n","      <td>['team', 'meeting', 'appear', 'calendar', 'adv...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                       0                                                  1\n","Short description                                            login issue                                            outlook\n","Description            login issue verify user detail employee manage...  outlook hello team meeting skype meeting etc a...\n","Caller                                                 spxjnwir pjlcoqds                                  hmjdrvpb komuaywn\n","Assignment group                                                   GRP_0                                              GRP_0\n","New_Assignment_Groups                                              GRP_0                                              GRP_0\n","Text_length                                                          206                                                194\n","Dominant_Topic                                                         1                                                  1\n","Topic_Perc_Contrib                                                0.9912                                             0.6753\n","Keywords               issue, tool, unable, user, error, work, access...  issue, tool, unable, user, error, work, access...\n","Text                   ['login', 'issue', 'verify', 'user', 'detail',...  ['team', 'meeting', 'appear', 'calendar', 'adv..."]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"n9K-LafvjcvU","colab_type":"code","colab":{}},"source":["data.dropna(subset=[data.columns[1]], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yyq-3BU0jcyj","colab_type":"text"},"source":["# Transformer Model (BERT)"]},{"cell_type":"markdown","metadata":{"id":"-baiibrz9L4N","colab_type":"text"},"source":["## STEP 1:  Load and Preprocess the Data\n","Preprocess the data using the `texts_from_df function` (since the data resides in an dataframe)."]},{"cell_type":"code","metadata":{"id":"VGrBhLmnjcyp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":275},"outputId":"a7d08811-a3b3-41f7-a57c-6132928de75e"},"source":["(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(data, \n","                                                                   'Description', # name of column containing review text\n","                                                                   label_columns=['Assignment group'],\n","                                                                   maxlen=250, \n","                                                                   max_features=10000,\n","                                                                   preprocess_mode='bert',\n","                                                                   val_pct=0.1,\n","                                                                   ngram_range=3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n","[██████████████████████████████████████████████████]\n","extracting pretrained BERT model...\n","done.\n","\n","cleanup downloaded zip...\n","done.\n","\n","preprocessing train...\n","language: en\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["done."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Is Multi-Label? False\n","preprocessing test...\n","language: en\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["done."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"orvFUXV09auF","colab_type":"text"},"source":["## STEP 2:  Load the BERT Model and Instantiate a Learner object"]},{"cell_type":"code","metadata":{"id":"Kyuc3DDXjcyr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"378b27c2-ef8f-4940-bf35-a50a1f6fa6e0"},"source":["model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)\n","learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Is Multi-Label? False\n","maxlen is 250\n","done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W7we6P9L9kXv","colab_type":"text"},"source":["## STEP 3: Train the Model\n","\n","We train using one of the three learning rates recommended in the BERT paper: *5e-5*, *3e-5*, or *2e-5*.\n","Alternatively, the ktrain Learning Rate Finder can be used to find a good learning rate by invoking `learner.lr_find()` and `learner.lr_plot()`, prior to training.\n","The `learner.fit_onecycle` method employs a [1cycle learning rate policy](https://arxiv.org/pdf/1803.09820.pdf)."]},{"cell_type":"code","metadata":{"id":"aMczzDZsjcyt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":447},"outputId":"38548cc6-4264-499f-d208-c1300311f82c"},"source":["learner.fit_onecycle(2e-5, 10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","begin training using onecycle policy with max lr of 2e-05...\n","Train on 7020 samples\n","Epoch 1/10\n","7020/7020 [==============================] - 542s 77ms/sample - loss: 2.6686 - accuracy: 0.4749\n","Epoch 2/10\n","7020/7020 [==============================] - 532s 76ms/sample - loss: 1.9345 - accuracy: 0.5630\n","Epoch 3/10\n","7020/7020 [==============================] - 531s 76ms/sample - loss: 1.5732 - accuracy: 0.6100\n","Epoch 4/10\n","7020/7020 [==============================] - 537s 77ms/sample - loss: 1.2647 - accuracy: 0.6775\n","Epoch 5/10\n","7020/7020 [==============================] - 537s 77ms/sample - loss: 0.9964 - accuracy: 0.7355\n","Epoch 6/10\n","7020/7020 [==============================] - 535s 76ms/sample - loss: 0.7262 - accuracy: 0.8024\n","Epoch 7/10\n","7020/7020 [==============================] - 535s 76ms/sample - loss: 0.5128 - accuracy: 0.8551\n","Epoch 8/10\n","7020/7020 [==============================] - 535s 76ms/sample - loss: 0.3733 - accuracy: 0.8989\n","Epoch 9/10\n","7020/7020 [==============================] - 535s 76ms/sample - loss: 0.3026 - accuracy: 0.9155\n","Epoch 10/10\n","7020/7020 [==============================] - 536s 76ms/sample - loss: 0.2616 - accuracy: 0.9261\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f887e780438>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"y0ktlZp29-Dp","colab_type":"text"},"source":["We can use the `learner.validate` method to test our model against the validation set. As we can see, BERT achieves a **92%** Training accuracy and **66%** Validation accuracy, which is quite a bit higher than the **57%** accuracy achieved by Random Forest DL model - HyperParameter tuned on unsampled data."]},{"cell_type":"code","metadata":{"id":"ufPssbyIjcyv","colab_type":"code","colab":{}},"source":["y_test_back = [i.argmax() for i in y_test]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QyoY4rJBjcyw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"57ca0176-93a2-4ef8-dc31-48876e10ef29"},"source":["learner.validate(val_data=(x_test, y_test), class_names=np.unique(y_test_back).all())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.75      0.92      0.83       329\n","           1       0.00      0.00      0.00         3\n","           2       0.56      0.56      0.56         9\n","           3       0.50      0.50      0.50         2\n","           4       0.57      0.55      0.56        31\n","           5       0.69      0.48      0.56        23\n","           6       0.31      0.45      0.37        11\n","           7       0.00      0.00      0.00         5\n","           8       0.57      0.50      0.53         8\n","           9       1.00      1.00      1.00         1\n","          10       0.83      0.50      0.62        10\n","          11       0.56      0.23      0.32        22\n","          12       0.36      0.25      0.29        20\n","          13       0.00      0.00      0.00         6\n","          14       0.50      0.40      0.44         5\n","          15       0.50      1.00      0.67         2\n","          16       0.33      1.00      0.50         2\n","          17       0.86      0.84      0.85        38\n","          18       0.67      0.46      0.55        13\n","          19       0.25      0.20      0.22         5\n","          20       0.00      0.00      0.00         2\n","          21       0.00      0.00      0.00         6\n","          22       0.80      0.67      0.73         6\n","          23       0.53      0.33      0.41        27\n","          24       0.00      0.00      0.00         1\n","          25       0.00      0.00      0.00         4\n","          27       0.50      0.57      0.53        14\n","          28       0.67      0.22      0.33         9\n","          30       0.00      0.00      0.00         1\n","          31       0.50      0.20      0.29         5\n","          33       0.00      0.00      0.00         3\n","          34       0.44      0.80      0.57         5\n","          35       0.25      0.25      0.25         4\n","          36       1.00      0.67      0.80         6\n","          37       0.20      0.14      0.17         7\n","          39       0.00      0.00      0.00         1\n","          40       0.00      0.00      0.00         3\n","          42       0.00      0.00      0.00         1\n","          44       0.00      0.00      0.00         2\n","          45       0.85      0.73      0.79        15\n","          49       0.00      0.00      0.00         1\n","          56       0.88      0.50      0.64        14\n","          57       0.00      0.00      0.00         4\n","          59       1.00      0.29      0.44         7\n","          62       0.00      0.00      0.00         2\n","          63       0.00      0.00      0.00         2\n","          67       0.50      0.67      0.57         6\n","          69       0.00      0.00      0.00         1\n","          70       0.00      0.00      0.00         1\n","          72       0.60      0.88      0.72        56\n","          73       0.24      0.20      0.22        20\n","\n","    accuracy                           0.66       781\n","   macro avg       0.37      0.33      0.33       781\n","weighted avg       0.62      0.66      0.63       781\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([[303,   0,   0, ...,   0,   0,   1],\n","       [  0,   0,   0, ...,   0,   0,   0],\n","       [  2,   0,   5, ...,   0,   1,   0],\n","       ...,\n","       [  1,   0,   0, ...,   0,   0,   0],\n","       [  0,   1,   0, ...,   0,  49,   4],\n","       [  0,   0,   0, ...,   0,  15,   4]])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"sZr_lzrsAGk4","colab_type":"text"},"source":["## How to Use Our Trained BERT Model\n","\n","We can call the `learner.get_predictor` method to obtain a Predictor object capable of making predictions on new raw data."]},{"cell_type":"code","metadata":{"id":"DxzOQneCjcyy","colab_type":"code","colab":{}},"source":["predictor = ktrain.get_predictor(learner.model, preproc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajzDIlkIjcyz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"29785e98-cecf-4227-a942-2127b54fb2d2"},"source":["predictor.get_classes()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['GRP_0',\n"," 'GRP_1',\n"," 'GRP_10',\n"," 'GRP_11',\n"," 'GRP_12',\n"," 'GRP_13',\n"," 'GRP_14',\n"," 'GRP_15',\n"," 'GRP_16',\n"," 'GRP_17',\n"," 'GRP_18',\n"," 'GRP_19',\n"," 'GRP_2',\n"," 'GRP_20',\n"," 'GRP_21',\n"," 'GRP_22',\n"," 'GRP_23',\n"," 'GRP_24',\n"," 'GRP_25',\n"," 'GRP_26',\n"," 'GRP_27',\n"," 'GRP_28',\n"," 'GRP_29',\n"," 'GRP_3',\n"," 'GRP_30',\n"," 'GRP_31',\n"," 'GRP_32',\n"," 'GRP_33',\n"," 'GRP_34',\n"," 'GRP_35',\n"," 'GRP_36',\n"," 'GRP_37',\n"," 'GRP_38',\n"," 'GRP_39',\n"," 'GRP_4',\n"," 'GRP_40',\n"," 'GRP_41',\n"," 'GRP_42',\n"," 'GRP_43',\n"," 'GRP_44',\n"," 'GRP_45',\n"," 'GRP_46',\n"," 'GRP_47',\n"," 'GRP_48',\n"," 'GRP_49',\n"," 'GRP_5',\n"," 'GRP_50',\n"," 'GRP_51',\n"," 'GRP_52',\n"," 'GRP_53',\n"," 'GRP_54',\n"," 'GRP_55',\n"," 'GRP_56',\n"," 'GRP_57',\n"," 'GRP_58',\n"," 'GRP_59',\n"," 'GRP_6',\n"," 'GRP_60',\n"," 'GRP_61',\n"," 'GRP_62',\n"," 'GRP_63',\n"," 'GRP_64',\n"," 'GRP_65',\n"," 'GRP_66',\n"," 'GRP_67',\n"," 'GRP_68',\n"," 'GRP_69',\n"," 'GRP_7',\n"," 'GRP_70',\n"," 'GRP_71',\n"," 'GRP_72',\n"," 'GRP_73',\n"," 'GRP_8',\n"," 'GRP_9']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"iNNs9vXwjcy0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"df1cd4ca-94a3-4ad7-9c14-f066a3c4fa82"},"source":["data['Description'].iloc[1013]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'netzteil oder netzstecker defekt pc wareneingang bitte netzteil oder netzstecker pc evhw wareneingang pr fen und ggf reparieren pc sst sich nur nach bewegen des steckers einschalten'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"GJyK4pZAjcy4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"685873a9-fa47-4b17-843e-3dfb8be4b4d2"},"source":["data['Assignment group'].iloc[1013]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'GRP_33'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"-NeNB3Cxjcy6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0269a4ce-44a7-4716-c5b9-c2c403a224f3"},"source":["#predictor.predict(test_data.iloc[1484].astype(str).values.tolist())\n","predictor.predict(data['Description'].iloc[1013])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'GRP_33'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"w4YHL-8eAVnm","colab_type":"text"},"source":["The `predictor.save` and `ktrain.load_predictor` methods can be used to save the Predictor object to disk and reload it at a later time to make predictions on new data."]},{"cell_type":"code","metadata":{"id":"TvFXrhQPjcy-","colab_type":"code","colab":{}},"source":["# let's save the predictor for later use\n","#predictor.save(os.path.join(capstone_project_path,'/my_predictor'))\n","predictor.save(project_path+'my_predictor')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykriDonsjczA","colab_type":"code","colab":{}},"source":["# reload the predictor\n","reloaded_predictor = ktrain.load_predictor(project_path+'my_predictor')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1br-kQW6jczC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4f7e74e0-c988-4e05-91ef-0056da0330f3"},"source":["reloaded_predictor.predict(data['Description'].iloc[1311])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'GRP_3'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Ms49KPLvjczD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"826ca124-d001-447d-e26e-5717a2aad9c8"},"source":["print(data['Assignment group'].iloc[1311])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRP_3\n"],"name":"stdout"}]}]}